2020-08-06 09:05:37 +0000 [info]: Received graceful stop
2020-08-06 09:05:38 +0000 [info]: #0 fluentd worker is now stopping worker=0
2020-08-06 09:05:38 +0000 [info]: #0 shutting down fluentd worker worker=0
2020-08-06 09:05:39 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2aab46fe632c"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2aab46e279a0"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down input plugin type=:forward plugin_id="input1"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab46a75cf8"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab470d8988"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab46e47444"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:relabel plugin_id="object:2aab46bf2900"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab46b875c4"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab472043c0"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab471fc760"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab46aa61f0"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab46a3c908"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab471e9b38"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab471c8a50"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab47144ea8"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab46eb2d70"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab46adaf04"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab47009084"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab470003a8"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab46b64f74"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab46e0b5c0"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab470a9df4"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab471df138"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab471c5288"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab470aca04"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab470df2c4"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab46e3f0f0"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab46e59f54"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab470e37c0"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab4713e42c"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2aab47108ef8"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab46dfb1d4"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab4709dab8"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab470a8d8c"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2aab46e4ac84"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down filter plugin type=:grep plugin_id="object:2aab46ff5a70"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:remote_syslog plugin_id="object:2aab46cb3fc4"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output_docker1"
2020-08-06 09:05:39 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output1"
2020-08-06 09:05:41 +0000 [info]: Worker 0 finished with status 0
fluent:x:1000:1000::/home/fluent:
2020-08-06 09:05:54 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2020-08-06 09:05:55 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:55 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:56 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-06 09:05:56 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-06 09:05:56 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2020-08-06 09:05:56 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2020-08-06 09:05:56 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2020-08-06 09:05:56 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2020-08-06 09:05:56 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2020-08-06 09:05:56 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2020-08-06 09:05:56 +0000 [info]: gem 'fluentd' version '1.1.3'
2020-08-06 09:05:56 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2020-08-06 09:05:56 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2020-08-06 09:05:56 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="eduid.me" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="simplesaml" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="db.postgres" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="office.erp" type="copy"
2020-08-06 09:05:57 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-06 09:05:57 +0000 [info]: adding match pattern="docker.**" type="copy"
2020-08-06 09:05:57 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-06 09:05:57 +0000 [info]: adding match pattern="**" type="file"
2020-08-06 09:05:57 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-06 09:05:57 +0000 [info]: adding source type="forward"
2020-08-06 09:05:57 +0000 [info]: adding source type="syslog"
2020-08-06 09:05:57 +0000 [info]: adding source type="syslog"
2020-08-06 09:05:57 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2020-08-06 09:05:57 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2020-08-06 09:05:57 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2020-08-06 09:05:57 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2020-08-06 09:05:57 +0000 [info]: #0 fluentd worker is now running worker=0
2020-08-25 10:02:14 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-08-26 20:47:40 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00+&\xE0\x00\x00\x00\x00\x00Cookie: mstshash=hello\r"
2020-08-29 10:50:23 +0000 [info]: Received graceful stop
2020-08-29 10:50:25 +0000 [info]: #0 fluentd worker is now stopping worker=0
2020-08-29 10:50:26 +0000 [warn]: #0 [output1] failed to write data into buffer by buffer overflow action=:throw_exception
2020-08-29 10:50:26 +0000 [warn]: #0 emit transaction failed: error_class=Fluent::Plugin::Buffer::BufferOverflowError error="can't create buffer metadata for /fluentd/log/data.*.log. Stop creating buffer files: error = No space left on device @ io_write - /fluentd/log/data.b5ae01efdaf59bedc93e902d95ebbf2d9.log.meta" location="/usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:296:in `rescue in create_new_chunk'" tag="fluent.info"
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:296:in `rescue in create_new_chunk'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:285:in `create_new_chunk'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:52:in `initialize'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buf_file.rb:169:in `new'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buf_file.rb:169:in `generate_chunk'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/out_file.rb:78:in `generate_chunk'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:549:in `block in write_once'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/2.4.0/monitor.rb:214:in `mon_synchronize'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:549:in `write_once'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:281:in `block in write'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:279:in `each'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:279:in `write'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:927:in `block in handle_stream_with_custom_format'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:853:in `write_guard'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:926:in `handle_stream_with_custom_format'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:845:in `execute_chunking'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:773:in `emit_buffered'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/event_router.rb:96:in `emit_stream'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/event_router.rb:87:in `emit'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:207:in `block in log_event_loop'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:205:in `each'
  2020-08-29 10:50:26 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:205:in `log_event_loop'
2020-08-29 10:50:26 +0000 [error]: #0 failed to emit fluentd's log event tag="fluent.info" event={"worker"=>0, "message"=>"fluentd worker is now stopping worker=0"} error_class=Fluent::Plugin::Buffer::BufferOverflowError error="can't create buffer metadata for /fluentd/log/data.*.log. Stop creating buffer files: error = No space left on device @ io_write - /fluentd/log/data.b5ae01efdaf59bedc93e902d95ebbf2d9.log.meta"
2020-08-29 10:50:26 +0000 [info]: #0 shutting down fluentd worker worker=0
2020-08-29 10:50:28 +0000 [info]: #0 shutting down input plugin type=:forward plugin_id="input1"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2b12e78a93e4"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2b12e76f85cc"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e738c17c"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e78c150c"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7712134"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:relabel plugin_id="object:2b12e74fbdf0"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e7448228"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e79d47c8"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e77379e8"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e73fa924"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7577ba8"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7970e58"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e7968f78"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e79700ac"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e796c204"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e7999b78"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e77041b0"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e7ab5408"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e77137dc"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7a64df0"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7a8c92c"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e7a04464"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e777a3ec"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e792a69c"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7abd25c"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e79aacc0"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e7a991b8"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7a0c1dc"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7335f5c"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e7473644"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e738c3e8"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e7a82508"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b12e799dfc0"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b12e76cf1f4"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down filter plugin type=:grep plugin_id="object:2b12e78b7b60"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:remote_syslog plugin_id="object:2b12e76a00c0"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output_docker1"
2020-08-29 10:50:29 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output1"
fluent:x:1000:1000::/home/fluent:
2020-08-29 10:50:44 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2020-08-29 10:50:46 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:49 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 10:50:49 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 10:50:49 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2020-08-29 10:50:49 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2020-08-29 10:50:49 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2020-08-29 10:50:50 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2020-08-29 10:50:50 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2020-08-29 10:50:50 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2020-08-29 10:50:50 +0000 [info]: gem 'fluentd' version '1.1.3'
2020-08-29 10:50:50 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2020-08-29 10:50:50 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2020-08-29 10:50:50 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2020-08-29 10:50:50 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="eduid.me" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="simplesaml" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="db.postgres" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="office.erp" type="copy"
2020-08-29 10:50:51 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:50:51 +0000 [info]: adding match pattern="docker.**" type="copy"
2020-08-29 10:50:51 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 10:50:51 +0000 [info]: adding match pattern="**" type="file"
2020-08-29 10:50:51 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 10:50:51 +0000 [info]: adding source type="forward"
2020-08-29 10:50:51 +0000 [info]: adding source type="syslog"
2020-08-29 10:50:51 +0000 [info]: adding source type="syslog"
2020-08-29 10:50:51 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2020-08-29 10:50:51 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2020-08-29 10:50:51 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2020-08-29 10:50:51 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2020-08-29 10:50:51 +0000 [info]: #0 fluentd worker is now running worker=0
2020-08-29 10:50:51 +0000 [warn]: #0 [output1] failed to write data into buffer by buffer overflow action=:throw_exception
2020-08-29 10:50:51 +0000 [warn]: #0 emit transaction failed: error_class=Fluent::Plugin::Buffer::BufferOverflowError error="can't create buffer metadata for /fluentd/log/data.*.log. Stop creating buffer files: error = No space left on device @ io_write - /fluentd/log/data.b5ae01f168ee600f598dbfa1f3dfe6c86.log.meta" location="/usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:296:in `rescue in create_new_chunk'" tag="fluent.info"
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:296:in `rescue in create_new_chunk'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:285:in `create_new_chunk'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:52:in `initialize'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buf_file.rb:169:in `new'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buf_file.rb:169:in `generate_chunk'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/out_file.rb:78:in `generate_chunk'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:549:in `block in write_once'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/2.4.0/monitor.rb:214:in `mon_synchronize'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:549:in `write_once'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:281:in `block in write'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:279:in `each'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:279:in `write'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:927:in `block in handle_stream_with_custom_format'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:853:in `write_guard'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:926:in `handle_stream_with_custom_format'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:845:in `execute_chunking'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:773:in `emit_buffered'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/event_router.rb:96:in `emit_stream'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/event_router.rb:87:in `emit'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:207:in `block in log_event_loop'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:205:in `each'
  2020-08-29 10:50:51 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:205:in `log_event_loop'
2020-08-29 10:50:51 +0000 [error]: #0 failed to emit fluentd's log event tag="fluent.info" event={"worker"=>0, "message"=>"fluentd worker is now running worker=0"} error_class=Fluent::Plugin::Buffer::BufferOverflowError error="can't create buffer metadata for /fluentd/log/data.*.log. Stop creating buffer files: error = No space left on device @ io_write - /fluentd/log/data.b5ae01f168ee600f598dbfa1f3dfe6c86.log.meta"
2020-08-29 10:51:39 +0000 [info]: Received graceful stop
2020-08-29 10:51:41 +0000 [info]: #0 fluentd worker is now stopping worker=0
2020-08-29 10:51:41 +0000 [warn]: #0 [output1] failed to write data into buffer by buffer overflow action=:throw_exception
2020-08-29 10:51:41 +0000 [warn]: #0 emit transaction failed: error_class=Fluent::Plugin::Buffer::BufferOverflowError error="can't create buffer metadata for /fluentd/log/data.*.log. Stop creating buffer files: error = No space left on device @ io_write - /fluentd/log/data.b5ae01f456e2dedfa789860261d7b5d49.log.meta" location="/usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:296:in `rescue in create_new_chunk'" tag="fluent.info"
  2020-08-29 10:51:41 +0000 [warn]: #0 suppressed same stacktrace
2020-08-29 10:51:41 +0000 [error]: #0 failed to emit fluentd's log event tag="fluent.info" event={"worker"=>0, "message"=>"fluentd worker is now stopping worker=0"} error_class=Fluent::Plugin::Buffer::BufferOverflowError error="can't create buffer metadata for /fluentd/log/data.*.log. Stop creating buffer files: error = No space left on device @ io_write - /fluentd/log/data.b5ae01f456e2dedfa789860261d7b5d49.log.meta"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down fluentd worker worker=0
2020-08-29 10:51:41 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2b0d9f2e8330"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down input plugin type=:forward plugin_id="input1"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2b0d9f414538"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f5adf48"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f90e020"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f8a2334"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f89ed9c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:relabel plugin_id="object:2b0d9f5a639c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f47593c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f469a4c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f8bd29c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f616674"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f5fac30"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f5eee80"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f8a9dc8"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f98dd5c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f8ff020"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f89849c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f7bc2f8"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f8fbf4c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f7ceae8"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f7c2b1c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f31e1b0"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f8ad0b8"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b0d9f2e5e8c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f2dd638"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f8a884c"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f986660"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f7b8068"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f2f45cc"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f627a50"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f8fa714"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f890d28"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f468b24"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b0d9f8ff5d4"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:remote_syslog plugin_id="object:2b0d9f2e8448"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down filter plugin type=:grep plugin_id="object:2b0d9f5ba914"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output_docker1"
2020-08-29 10:51:41 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output1"
2020-08-29 10:51:41 +0000 [info]: Worker 0 finished with status 0
fluent:x:1000:1000::/home/fluent:
2020-08-29 10:55:12 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2020-08-29 10:55:14 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:18 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 10:55:18 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 10:55:18 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2020-08-29 10:55:18 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2020-08-29 10:55:18 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2020-08-29 10:55:19 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2020-08-29 10:55:19 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2020-08-29 10:55:19 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2020-08-29 10:55:19 +0000 [info]: gem 'fluentd' version '1.1.3'
2020-08-29 10:55:19 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2020-08-29 10:55:19 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2020-08-29 10:55:19 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2020-08-29 10:55:19 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:19 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2020-08-29 10:55:19 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:19 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2020-08-29 10:55:19 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:19 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2020-08-29 10:55:19 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:19 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2020-08-29 10:55:19 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:20 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2020-08-29 10:55:20 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:20 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2020-08-29 10:55:20 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:20 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2020-08-29 10:55:20 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:20 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2020-08-29 10:55:20 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:20 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2020-08-29 10:55:20 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:20 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2020-08-29 10:55:20 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:20 +0000 [info]: adding match pattern="eduid.me" type="copy"
2020-08-29 10:55:20 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:20 +0000 [info]: adding match pattern="simplesaml" type="copy"
2020-08-29 10:55:20 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:21 +0000 [info]: adding match pattern="db.postgres" type="copy"
2020-08-29 10:55:21 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:21 +0000 [info]: adding match pattern="office.erp" type="copy"
2020-08-29 10:55:21 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 10:55:21 +0000 [info]: adding match pattern="docker.**" type="copy"
2020-08-29 10:55:21 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 10:55:21 +0000 [info]: adding match pattern="**" type="file"
2020-08-29 10:55:21 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 10:55:21 +0000 [info]: adding source type="forward"
2020-08-29 10:55:21 +0000 [info]: adding source type="syslog"
2020-08-29 10:55:21 +0000 [info]: adding source type="syslog"
2020-08-29 10:55:21 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2020-08-29 10:55:21 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2020-08-29 10:55:21 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2020-08-29 10:55:21 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2020-08-29 10:55:21 +0000 [info]: #0 fluentd worker is now running worker=0
2020-08-29 10:55:21 +0000 [warn]: #0 [output1] failed to write data into buffer by buffer overflow action=:throw_exception
2020-08-29 10:55:21 +0000 [warn]: #0 emit transaction failed: error_class=Fluent::Plugin::Buffer::BufferOverflowError error="can't create buffer metadata for /fluentd/log/data.*.log. Stop creating buffer files: error = No space left on device @ io_write - /fluentd/log/data.b5ae020179d7eb31ed6ea7cbf90869abb.log.meta" location="/usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:296:in `rescue in create_new_chunk'" tag="fluent.info"
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:296:in `rescue in create_new_chunk'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:285:in `create_new_chunk'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer/file_chunk.rb:52:in `initialize'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buf_file.rb:169:in `new'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buf_file.rb:169:in `generate_chunk'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/out_file.rb:78:in `generate_chunk'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:549:in `block in write_once'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/2.4.0/monitor.rb:214:in `mon_synchronize'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:549:in `write_once'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:281:in `block in write'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:279:in `each'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/buffer.rb:279:in `write'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:927:in `block in handle_stream_with_custom_format'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:853:in `write_guard'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:926:in `handle_stream_with_custom_format'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:845:in `execute_chunking'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:773:in `emit_buffered'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/event_router.rb:96:in `emit_stream'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/event_router.rb:87:in `emit'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:207:in `block in log_event_loop'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:205:in `each'
  2020-08-29 10:55:21 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/engine.rb:205:in `log_event_loop'
2020-08-29 10:55:21 +0000 [error]: #0 failed to emit fluentd's log event tag="fluent.info" event={"worker"=>0, "message"=>"fluentd worker is now running worker=0"} error_class=Fluent::Plugin::Buffer::BufferOverflowError error="can't create buffer metadata for /fluentd/log/data.*.log. Stop creating buffer files: error = No space left on device @ io_write - /fluentd/log/data.b5ae020179d7eb31ed6ea7cbf90869abb.log.meta"
2020-08-29 11:24:18 +0000 [info]: Received graceful stop
2020-08-29 11:24:19 +0000 [info]: #0 fluentd worker is now stopping worker=0
2020-08-29 11:24:19 +0000 [info]: #0 shutting down fluentd worker worker=0
2020-08-29 11:24:19 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2ad8749379f8"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down input plugin type=:forward plugin_id="input1"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2ad874b23a50"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad8744fd1f8"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad87455022c"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad8748ead60"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:relabel plugin_id="object:2ad8746f3da4"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad8746c2948"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad87467d3c0"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874bd7d70"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874bd6178"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874665e28"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad8745ce208"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad87494ab84"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874c8db0c"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874c88ecc"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874b8b650"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874b76d7c"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874b71818"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874b0ca08"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874afbb40"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad8748da884"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874584acc"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874a848b0"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874a7c5fc"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874a78c68"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874680854"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874bc6228"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874c21254"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874b6d6c8"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad8745fd7d8"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874c032a4"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ad874b17c28"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad8744d4050"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ad874c1aee0"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down filter plugin type=:grep plugin_id="object:2ad874a85e68"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:remote_syslog plugin_id="object:2ad874862244"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output_docker1"
2020-08-29 11:24:19 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output1"
2020-08-29 11:24:19 +0000 [info]: Worker 0 finished with status 0
fluent:x:1000:1000::/home/fluent:
2020-08-29 11:25:52 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2020-08-29 11:25:53 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:54 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:25:54 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:25:54 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2020-08-29 11:25:54 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2020-08-29 11:25:54 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2020-08-29 11:25:54 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2020-08-29 11:25:54 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2020-08-29 11:25:54 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2020-08-29 11:25:54 +0000 [info]: gem 'fluentd' version '1.1.3'
2020-08-29 11:25:54 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2020-08-29 11:25:54 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2020-08-29 11:25:54 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="eduid.me" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="simplesaml" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="db.postgres" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="office.erp" type="copy"
2020-08-29 11:25:55 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:25:55 +0000 [info]: adding match pattern="docker.**" type="copy"
2020-08-29 11:25:55 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:25:55 +0000 [info]: adding match pattern="**" type="file"
2020-08-29 11:25:55 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:25:55 +0000 [info]: adding source type="forward"
2020-08-29 11:25:55 +0000 [info]: adding source type="syslog"
2020-08-29 11:25:55 +0000 [info]: adding source type="syslog"
2020-08-29 11:25:55 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2020-08-29 11:25:55 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2020-08-29 11:25:55 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2020-08-29 11:25:55 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2020-08-29 11:25:55 +0000 [info]: #0 fluentd worker is now running worker=0
2020-08-29 11:27:10 +0000 [info]: Received graceful stop
2020-08-29 11:27:11 +0000 [info]: #0 fluentd worker is now stopping worker=0
2020-08-29 11:27:11 +0000 [info]: #0 shutting down fluentd worker worker=0
2020-08-29 11:27:11 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2b15543f3d94"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down input plugin type=:forward plugin_id="input1"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2b15545bc52c"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b1554484e98"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b15546b931c"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b15545e1200"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b155441b574"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:relabel plugin_id="object:2b15541ce064"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b155414b768"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b15546e5408"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15546bda0c"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b155400a2f0"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15546a0bc8"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b155479cdc4"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15547993e0"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b15540434c4"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15545d8614"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b15547d4288"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b15544490b4"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b1554047740"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b155466a80c"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b1554720e18"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b1554684914"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b1554680d14"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b155440d398"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b155441eeb8"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b15547b97a8"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b1554172d04"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15547cc754"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2b15543db460"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15547b0fe0"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15546b0a3c"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15543cac50"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b15540ced94"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2b155471a284"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down filter plugin type=:grep plugin_id="object:2b15545c9ccc"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:remote_syslog plugin_id="object:2b15543adab0"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output1"
2020-08-29 11:27:11 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output_docker1"
2020-08-29 11:27:12 +0000 [info]: Worker 0 finished with status 0
fluent:x:1000:1000::/home/fluent:
2020-08-29 11:27:59 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:27:59 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:27:59 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:27:59 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2020-08-29 11:27:59 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2020-08-29 11:27:59 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2020-08-29 11:28:00 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2020-08-29 11:28:00 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2020-08-29 11:28:00 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2020-08-29 11:28:00 +0000 [info]: gem 'fluentd' version '1.1.3'
2020-08-29 11:28:00 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2020-08-29 11:28:00 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="eduid.me" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="simplesaml" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="db.postgres" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="office.erp" type="copy"
2020-08-29 11:28:00 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:28:00 +0000 [info]: adding match pattern="docker.**" type="copy"
2020-08-29 11:28:00 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:28:00 +0000 [info]: adding match pattern="**" type="file"
2020-08-29 11:28:00 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:28:00 +0000 [info]: adding source type="forward"
2020-08-29 11:28:00 +0000 [info]: adding source type="syslog"
2020-08-29 11:28:00 +0000 [info]: adding source type="syslog"
2020-08-29 11:28:00 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2020-08-29 11:28:00 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2020-08-29 11:28:00 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2020-08-29 11:28:00 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2020-08-29 11:28:00 +0000 [info]: #0 fluentd worker is now running worker=0
2020-08-29 11:29:09 +0000 [info]: Received graceful stop
2020-08-29 11:29:10 +0000 [info]: #0 fluentd worker is now stopping worker=0
2020-08-29 11:29:10 +0000 [info]: #0 shutting down fluentd worker worker=0
2020-08-29 11:29:10 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2ab8e77152f8"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down input plugin type=:forward plugin_id="input1"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2ab8e77dbf5c"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e772e53c"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7daf99c"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7a84df8"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e78915b4"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:relabel plugin_id="object:2ab8e7ddcac8"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7dd1718"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7d62570"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7cb1d88"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7bdc6b0"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7a5e928"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e77ce370"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e76245ec"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7a7860c"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7a632ac"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7a28030"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7a474f8"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7c5a2b8"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7be9874"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e784cd60"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7dd005c"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7ca789c"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7a50238"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7ce1b78"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e761d364"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e76d8150"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7629bdc"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7d596b4"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e77bbaf4"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7cc2b9c"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ab8e7c5e5fc"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7bd1d28"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ab8e7a786fc"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down filter plugin type=:grep plugin_id="object:2ab8e7c6c3dc"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:remote_syslog plugin_id="object:2ab8e7a42728"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output1"
2020-08-29 11:29:10 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output_docker1"
2020-08-29 11:29:11 +0000 [info]: Worker 0 finished with status 0
fluent:x:1000:1000::/home/fluent:
2020-08-29 11:32:31 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2020-08-29 11:32:33 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:34 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:32:34 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:32:34 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2020-08-29 11:32:34 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2020-08-29 11:32:34 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2020-08-29 11:32:35 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2020-08-29 11:32:35 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2020-08-29 11:32:35 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2020-08-29 11:32:35 +0000 [info]: gem 'fluentd' version '1.1.3'
2020-08-29 11:32:35 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2020-08-29 11:32:35 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="eduid.me" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="simplesaml" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="db.postgres" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="office.erp" type="copy"
2020-08-29 11:32:35 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2020-08-29 11:32:35 +0000 [info]: adding match pattern="docker.**" type="copy"
2020-08-29 11:32:35 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:32:35 +0000 [info]: adding match pattern="**" type="file"
2020-08-29 11:32:35 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2020-08-29 11:32:35 +0000 [info]: adding source type="forward"
2020-08-29 11:32:35 +0000 [info]: adding source type="syslog"
2020-08-29 11:32:35 +0000 [info]: adding source type="syslog"
2020-08-29 11:32:35 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2020-08-29 11:32:35 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2020-08-29 11:32:35 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2020-08-29 11:32:35 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2020-08-29 11:32:35 +0000 [info]: #0 fluentd worker is now running worker=0
2020-09-04 08:35:09 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-09-11 10:05:03 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-09-26 02:02:08 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-10-02 07:01:51 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-10-29 16:35:49 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-10-30 18:48:37 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-11-01 02:29:05 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-11-02 08:11:27 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-11-22 08:52:32 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-11-22 08:57:49 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2020-11-26 19:25:34 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00+&\xE0\x00\x00\x00\x00\x00Cookie: mstshash=hello\r"
2020-12-20 00:11:50 +0000 [warn]: #0 failed to parse message data="HEAD / HTTP/1.1\r"
2020-12-20 00:11:50 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2020-12-20 00:11:50 +0000 [warn]: #0 failed to parse message data="Connection: keep-alive\r"
2020-12-20 00:11:50 +0000 [warn]: #0 failed to parse message data="Accept-Encoding: gzip, deflate\r"
2020-12-20 00:11:50 +0000 [warn]: #0 failed to parse message data="Accept: */*\r"
2020-12-20 00:11:50 +0000 [warn]: #0 failed to parse message data="User-Agent: python-requests/2.25.0\r"
2020-12-20 00:11:50 +0000 [warn]: #0 failed to parse message data="\r"
2020-12-20 00:17:47 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2020-12-20 00:17:47 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2020-12-20 00:17:47 +0000 [warn]: #0 failed to parse message data="Connection: keep-alive\r"
2020-12-20 00:17:47 +0000 [warn]: #0 failed to parse message data="Accept-Encoding: gzip, deflate\r"
2020-12-20 00:17:47 +0000 [warn]: #0 failed to parse message data="Accept: */*\r"
2020-12-20 00:17:47 +0000 [warn]: #0 failed to parse message data="User-Agent: python-requests/2.25.0\r"
2020-12-20 00:17:47 +0000 [warn]: #0 failed to parse message data="\r"
2020-12-20 01:03:26 +0000 [warn]: #0 failed to parse message data=""
2020-12-20 01:03:26 +0000 [warn]: #0 failed to parse message data=""
2020-12-20 01:03:26 +0000 [warn]: #0 failed to parse message data=""
2021-01-11 16:47:40 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-01-31 22:49:46 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=3
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=47
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=42
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=-32
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=67
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=111
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=111
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=107
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=105
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=101
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=58
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=32
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=109
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=115
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=116
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=115
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=104
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=97
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=115
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=104
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=61
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=65
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=100
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=109
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=105
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=110
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=105
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=115
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=116
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=114
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=13
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=10
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=1
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=8
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=3
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:30:11 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=3
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=37
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=2
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=-16
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg={}
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=100
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=3
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=-21
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=112
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg={}
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=22
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=22
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=23
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=-23
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=3
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=1
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=8
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=36
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=1
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=-22
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=3
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=3
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=0
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=9
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=2
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=-16
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg={}
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=32
2021-02-12 00:31:54 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.1.82" msg=3
2021-02-18 21:11:29 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-03-05 06:04:52 +0000 [info]: #0 Connection opened to Elasticsearch cluster => {:host=>"elasticsearch", :port=>9200, :scheme=>"http"}
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=22
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=3
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=1
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=0
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=123
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=1
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=0
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=0
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=119
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=3
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=3
2021-03-06 13:09:19 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=113
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=71
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=69
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=84
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=32
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=47
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=32
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=72
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=84
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=84
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=80
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=47
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=49
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=46
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=49
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=13
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=10
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=72
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=111
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=115
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=116
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=58
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=32
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=49
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=50
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=57
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=46
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=50
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=51
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=50
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=46
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=50
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=51
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=48
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=46
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=49
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=51
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=49
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=58
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=50
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=52
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=50
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=50
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=52
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=13
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=10
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=13
2021-03-06 13:09:23 +0000 [warn]: #0 [input1] incoming chunk is broken: host="162.142.125.96" msg=10
2021-03-17 13:43:32 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-03-20 07:56:18 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03\xC5\xA8\x10|\xE9\xA7S\xAB4D\xD2\xFA\xFBN\xDC|\xE3S\xA8\x16\x05(T\x93\x9AX\x84\x9F\xBAH\x8B\xF8\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-03-20 07:56:18 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-03-20 07:56:18 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-03-20 07:56:22 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-03-20 07:56:22 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-03-20 07:56:22 +0000 [warn]: #0 failed to parse message data="\r"
fluent:x:1000:1000::/home/fluent:
2021-03-29 11:36:37 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2021-03-29 11:36:40 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:41 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2021-03-29 11:36:41 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2021-03-29 11:36:41 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2021-03-29 11:36:41 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2021-03-29 11:36:41 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2021-03-29 11:36:42 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2021-03-29 11:36:42 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2021-03-29 11:36:42 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2021-03-29 11:36:42 +0000 [info]: gem 'fluentd' version '1.1.3'
2021-03-29 11:36:42 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2021-03-29 11:36:42 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="eduid.me" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="simplesaml" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="db.postgres" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="office.erp" type="copy"
2021-03-29 11:36:42 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-03-29 11:36:42 +0000 [info]: adding match pattern="docker.**" type="copy"
2021-03-29 11:36:42 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2021-03-29 11:36:42 +0000 [info]: adding match pattern="**" type="file"
2021-03-29 11:36:42 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2021-03-29 11:36:42 +0000 [info]: adding source type="forward"
2021-03-29 11:36:42 +0000 [info]: adding source type="syslog"
2021-03-29 11:36:42 +0000 [info]: adding source type="syslog"
2021-03-29 11:36:42 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2021-03-29 11:36:42 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2021-03-29 11:36:42 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2021-03-29 11:36:42 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2021-03-29 11:36:42 +0000 [info]: #0 fluentd worker is now running worker=0
2021-03-31 12:39:22 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-04-01 15:35:52 +0000 [info]: #0 Connection opened to Elasticsearch cluster => {:host=>"elasticsearch", :port=>9200, :scheme=>"http"}
2021-04-04 00:49:57 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-04-29 17:52:52 +0000 [info]: Received graceful stop
2021-04-29 17:52:52 +0000 [info]: #0 fluentd worker is now stopping worker=0
2021-04-29 17:52:52 +0000 [info]: #0 shutting down fluentd worker worker=0
2021-04-29 17:52:52 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2ada3989e5fc"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down input plugin type=:forward plugin_id="input1"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2ada399fbb70"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada3978d884"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39d483b4"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39f3f3fc"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39e49010"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39b9e018"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada399ac994"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39868efc"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39ea2200"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39d59e5c"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39a07ca4"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39b883bc"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39eda2cc"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39dcab48"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39d5ca08"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada3999747c"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39bf9ecc"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39f24804"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39d4e3cc"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:relabel plugin_id="object:2ada39784af4"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada3997249c"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39f3ba90"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39b936cc"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39d33a7c"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada398ac260"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39e94290"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39b8c6c4"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada39ee0834"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39e448a8"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada3989ba00"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada3997f7f0"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ada39801888"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ada3998e9d0"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:remote_syslog plugin_id="object:2ada39a02290"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down filter plugin type=:grep plugin_id="object:2ada39d45ce0"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output_docker1"
2021-04-29 17:52:52 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output1"
2021-04-29 17:52:53 +0000 [info]: Worker 0 finished with status 0
fluent:x:1000:1000::/home/fluent:
2021-04-29 17:56:17 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:21 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:22 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2021-04-29 17:56:22 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2021-04-29 17:56:22 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2021-04-29 17:56:22 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2021-04-29 17:56:22 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2021-04-29 17:56:22 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2021-04-29 17:56:22 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2021-04-29 17:56:22 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2021-04-29 17:56:22 +0000 [info]: gem 'fluentd' version '1.1.3'
2021-04-29 17:56:22 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2021-04-29 17:56:22 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2021-04-29 17:56:22 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="eduid.me" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="simplesaml" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="db.postgres" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="office.erp" type="copy"
2021-04-29 17:56:23 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-04-29 17:56:23 +0000 [info]: adding match pattern="docker.**" type="copy"
2021-04-29 17:56:23 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2021-04-29 17:56:23 +0000 [info]: adding match pattern="**" type="file"
2021-04-29 17:56:23 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2021-04-29 17:56:23 +0000 [info]: adding source type="forward"
2021-04-29 17:56:23 +0000 [info]: adding source type="syslog"
2021-04-29 17:56:23 +0000 [info]: adding source type="syslog"
2021-04-29 17:56:23 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2021-04-29 17:56:23 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2021-04-29 17:56:23 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2021-04-29 17:56:23 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2021-04-29 17:56:23 +0000 [info]: #0 fluentd worker is now running worker=0
2021-04-30 02:46:15 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-04-30 18:11:22 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-05-04 11:34:34 +0000 [info]: #0 Connection opened to Elasticsearch cluster => {:host=>"elasticsearch", :port=>9200, :scheme=>"http"}
2021-05-21 03:51:44 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-07-12 19:41:27 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03\x9D\xCF\xB5\x1A\xD3\x994w\xB9q\xAD\x05\v^D\x8A\x9Fs\x91\x83\xD7\t\x9Eu\xE5\xBA\xEAi\x15\xCAT\xA0\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-07-12 19:41:27 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-07-12 19:41:27 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-07-12 19:41:32 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-07-12 19:41:32 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-07-12 19:41:32 +0000 [warn]: #0 failed to parse message data="\r"
2021-07-13 05:48:39 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03|6\x8D\x0F\xF0,\x00\xAD\xF3\xDB\xCF\x88\xF9\x1E \x04\x98\x8E\xF4\xEA\xB6`\xEF\x84\x87S\x98\xB9\v\xC3{W\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-07-13 05:48:39 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-07-13 05:48:39 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-07-13 05:48:44 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-07-13 05:48:44 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-07-13 05:48:44 +0000 [warn]: #0 failed to parse message data="\r"
2021-07-13 05:51:53 +0000 [warn]: #0 failed to parse message data="\r"
2021-07-13 05:51:55 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-07-13 05:51:55 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-07-13 05:51:55 +0000 [warn]: #0 failed to parse message data="\r"
2021-07-13 05:51:56 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03\xA6\xF3\xCC(\x89\xD6\x03\xCE\xBC\x92\x8F\xBE\xAF\f\xE5\xC6\xFF\x81\x06y!\xBB\a\xC3k\xF5/\x7F\xA1a\xB8J \vs\xE0\x91T\"Yj\xF3\xF4\x94\xFC\xE6tD\x9C\r\x9E(\x96\xCA\xD9\xA3P\xD7\xBA\xA01A'\xA0\x88\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-07-13 05:51:56 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-07-13 05:51:56 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-07-13 05:51:56 +0000 [warn]: #0 failed to parse message data="\x00"
2021-07-13 16:01:03 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=3
2021-07-13 16:01:03 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:03 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:03 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=47
2021-07-13 16:01:03 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=42
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=-32
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=67
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=111
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=111
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=107
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=105
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=101
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=58
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=32
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=109
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=115
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=116
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=115
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=104
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=97
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=115
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=104
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=61
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=65
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=100
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=109
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=105
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=110
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=105
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=115
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=116
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=114
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=13
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=10
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=1
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=8
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=3
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:01:04 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=3
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=37
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=2
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=-16
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg={}
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=100
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=3
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=-21
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=112
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg={}
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=22
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=22
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=23
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=-23
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=3
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=1
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=8
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=36
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=1
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=-22
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=3
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=3
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=0
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=9
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=2
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=-16
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg={}
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=32
2021-07-13 16:02:46 +0000 [warn]: #0 [input1] incoming chunk is broken: host="185.202.2.32" msg=3
2021-07-14 15:23:19 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-07-14 15:24:47 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=3
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=47
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=42
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=-32
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=67
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=111
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=111
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=107
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=105
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=101
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=58
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=32
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=109
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=115
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=116
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=115
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=104
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=97
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=115
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=104
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=61
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=65
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=100
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=109
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=105
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=110
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=105
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=115
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=116
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=114
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=13
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=10
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=1
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=8
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=3
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:42:30 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.156" msg=0
2021-07-19 23:56:44 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-07-20 03:29:03 +0000 [warn]: #0 failed to parse message data="\r"
2021-07-20 05:52:34 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-07-20 16:12:51 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-07-20 16:46:09 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-07-27 10:32:44 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03z`\x0E\xE6x2\x9F\xA2x7A\x1FUfRV\x06\xF9\x92\x1D\x9E(FVz\x81J\xDFd\xEB\xAF\xFC\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-07-27 10:32:44 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-07-27 10:32:44 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-07-27 10:32:48 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-07-27 10:32:48 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-07-27 10:32:48 +0000 [warn]: #0 failed to parse message data="\r"
2021-07-29 14:21:58 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=3
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=47
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=42
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=-32
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=67
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=111
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=111
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=107
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=101
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=58
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=32
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=109
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=116
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=104
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=97
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=104
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=61
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=65
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=100
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=109
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=110
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=116
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=114
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=13
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=10
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=1
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=8
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=3
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-06 15:55:26 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-08-17 07:40:42 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03S\xCF\xE4\x11j\xFF\xA53\x91\xC3\x83q\xF4\xE6]i\xE4\xF1\x9F\xAB\xDE)\xBA\xFDD\xD0\x81@O\xD5+\xA7\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-08-17 07:40:42 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-08-17 07:40:42 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-08-17 07:40:46 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-08-17 07:40:46 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-08-17 07:40:46 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-18 10:28:04 +0000 [info]: Received graceful stop
2021-08-18 10:28:05 +0000 [info]: #0 fluentd worker is now stopping worker=0
2021-08-18 10:28:05 +0000 [info]: #0 shutting down fluentd worker worker=0
2021-08-18 10:28:05 +0000 [info]: #0 shutting down input plugin type=:forward plugin_id="input1"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2ae4db82ba8c"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down input plugin type=:syslog plugin_id="object:2ae4db8090cc"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db275548"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4dadffa18"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db44a0bc"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db444130"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:relabel plugin_id="object:2ae4db2cd590"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db2b40f4"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db0eeae4"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4dae25d30"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4dae14058"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db2c0854"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4daedb25c"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4daf1a77c"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db0a3814"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db4676bc"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db34db28"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db35b778"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db389ac4"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4dadf7020"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db39dfd8"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db2ad3f8"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db4325e8"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db2ad1c8"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db36e6c0"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db35b73c"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db3d55c8"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db3b1628"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db0e1628"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4dae5d0dc"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db45e9cc"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db347e80"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:elasticsearch plugin_id="object:2ae4db41f344"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:copy plugin_id="object:2ae4db3db824"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:remote_syslog plugin_id="object:2ae4db40cdd4"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down filter plugin type=:grep plugin_id="object:2ae4dae20d80"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output1"
2021-08-18 10:28:05 +0000 [info]: #0 shutting down output plugin type=:file plugin_id="output_docker1"
2021-08-18 10:28:06 +0000 [info]: Worker 0 finished with status 0
fluent:x:1000:1000::/home/fluent:
2021-08-18 10:34:25 +0000 [info]: parsing config file is succeeded path="/fluentd/etc/fluent.conf"
2021-08-18 10:34:25 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [info]: 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:26 +0000 [warn]: [output_docker1] 'time_format' specified without 'time_key', will be ignored
2021-08-18 10:34:26 +0000 [warn]: [output1] 'time_format' specified without 'time_key', will be ignored
2021-08-18 10:34:26 +0000 [info]: using configuration file: <ROOT>
  <source>
    @type forward
    @id input1
    port 24224
    bind "0.0.0.0"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type tcp
    tag "simplesaml"
  </source>
  <source>
    @type syslog
    port 5140
    bind "0.0.0.0"
    protocol_type udp
    tag "simplesaml"
  </source>
  <match eduroam.switchboard>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "switchboard"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-switchboard"
      type_name "switchboard_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.rps>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "rps"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-rps"
      type_name "rps_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.idp-ubuntunet>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "idp-ubuntunet"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-idp_ubuntunet"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
    <store>
      @type "relabel"
      @label @FTICKS
    </store>
  </match>
  <label @FTICKS>
    <filter eduroam.idp-ubuntunet>
      @type grep
      <regexp>
        key "log"
        pattern VISCOUNTRY=mw
      </regexp>
    </filter>
    <match eduroam.idp-ubuntunet>
      @type remote_syslog
      host "161.53.2.204"
      port 514
      severity "info"
      program "idp-ubuntunet"
      <format>
        @type "single_value"
        message_key "log"
      </format>
    </match>
  </label>
  <match eduroam.flr-zw>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-zw"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_zw"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-tz>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-tz"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_tz"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-et>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-et"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_et"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduroam.flr-mg>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "flr-mg"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduroam-flr_mg"
      type_name "flr_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.africa>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-africa"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-africa"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unida.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unida-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unida-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.unidame.discovery>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "unidame-discovery"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "unidame-discovery"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match eduid.me>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "eduid-me"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "eduid-me"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match simplesaml>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "simplesaml"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "simplesaml"
      type_name "eduid_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match db.postgres>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "db-postgres"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "db-postgres"
      type_name "db-postgres"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match office.erp>
    @type copy
    <store>
      @type "elasticsearch"
      host "elasticsearch"
      port 9200
      logstash_format true
      logstash_prefix "office-erp"
      logstash_dateformat "%Y%m%d"
      include_tag_key true
      tag_key "component"
      index_name "office-erp"
      type_name "office_log"
      flush_interval 1s
      <buffer>
        flush_interval 1s
      </buffer>
    </store>
  </match>
  <match docker.**>
    @type copy
    <store>
      @type "file"
      @id output_docker1
      path "/fluentd/log/docker.*.log"
      symlink_path "/fluentd/log/docker.log"
      append true
      time_slice_format %Y%m%d
      time_slice_wait 1m
      time_format %Y%m%dT%H%M%S%z
      <buffer time>
        timekey_wait 1m
        timekey 86400
        path /fluentd/log/docker.*.log
      </buffer>
      <inject>
        time_format %Y%m%dT%H%M%S%z
      </inject>
    </store>
  </match>
  <match **>
    @type file
    @id output1
    path "/fluentd/log/data.*.log"
    symlink_path "/fluentd/log/data.log"
    append true
    time_slice_format %Y%m%d
    time_slice_wait 10m
    time_format %Y%m%dT%H%M%S%z
    <buffer time>
      timekey_wait 10m
      timekey 86400
      path /fluentd/log/data.*.log
    </buffer>
    <inject>
      time_format %Y%m%dT%H%M%S%z
    </inject>
  </match>
</ROOT>
2021-08-18 10:34:26 +0000 [info]: starting fluentd-1.1.3 pid=6 ruby="2.4.4"
2021-08-18 10:34:26 +0000 [info]: spawn command to main:  cmdline=["/usr/bin/ruby", "-Eascii-8bit:ascii-8bit", "/usr/bin/fluentd", "-c", "/fluentd/etc/fluent.conf", "-p", "/fluentd/plugins", "--under-supervisor"]
2021-08-18 10:34:26 +0000 [info]: gem 'fluent-plugin-elasticsearch' version '2.10.0'
2021-08-18 10:34:26 +0000 [info]: gem 'fluent-plugin-remote_syslog' version '1.0.0'
2021-08-18 10:34:26 +0000 [info]: gem 'fluent-plugin-tagged_udp' version '0.0.7'
2021-08-18 10:34:26 +0000 [info]: gem 'fluentd' version '1.1.3'
2021-08-18 10:34:26 +0000 [info]: adding filter in @FTICKS pattern="eduroam.idp-ubuntunet" type="grep"
2021-08-18 10:34:26 +0000 [info]: adding match in @FTICKS pattern="eduroam.idp-ubuntunet" type="remote_syslog"
2021-08-18 10:34:26 +0000 [info]: adding match pattern="eduroam.switchboard" type="copy"
2021-08-18 10:34:26 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduroam.rps" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduroam.flr-mw" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduroam.idp-ubuntunet" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduroam.flr-zw" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduroam.flr-tz" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduroam.flr-et" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduroam.flr-mg" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduid.africa" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduid.unida.discovery" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduid.unidame.discovery" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="eduid.me" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="simplesaml" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="db.postgres" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="office.erp" type="copy"
2021-08-18 10:34:27 +0000 [info]: #0 'flush_interval' is configured at out side of <buffer>. 'flush_mode' is set to 'interval' to keep existing behaviour
2021-08-18 10:34:27 +0000 [info]: adding match pattern="docker.**" type="copy"
2021-08-18 10:34:27 +0000 [warn]: #0 [output_docker1] 'time_format' specified without 'time_key', will be ignored
2021-08-18 10:34:27 +0000 [info]: adding match pattern="**" type="file"
2021-08-18 10:34:27 +0000 [warn]: #0 [output1] 'time_format' specified without 'time_key', will be ignored
2021-08-18 10:34:27 +0000 [info]: adding source type="forward"
2021-08-18 10:34:27 +0000 [info]: adding source type="syslog"
2021-08-18 10:34:27 +0000 [info]: adding source type="syslog"
2021-08-18 10:34:27 +0000 [info]: #0 starting fluentd worker pid=17 ppid=6 worker=0
2021-08-18 10:34:27 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with udp
2021-08-18 10:34:27 +0000 [info]: #0 listening syslog socket on 0.0.0.0:5140 with tcp
2021-08-18 10:34:27 +0000 [info]: #0 [input1] listening port port=24224 bind="0.0.0.0"
2021-08-18 10:34:27 +0000 [info]: #0 fluentd worker is now running worker=0
2021-08-21 14:56:52 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-08-21 14:56:53 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:56:52 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluent-plugin-elasticsearch-2.10.0/lib/fluent/plugin/out_elasticsearch.rb:256:in `client'
  2021-08-21 14:56:52 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluent-plugin-elasticsearch-2.10.0/lib/fluent/plugin/out_elasticsearch.rb:514:in `rescue in send_bulk'
  2021-08-21 14:56:52 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluent-plugin-elasticsearch-2.10.0/lib/fluent/plugin/out_elasticsearch.rb:506:in `send_bulk'
  2021-08-21 14:56:52 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluent-plugin-elasticsearch-2.10.0/lib/fluent/plugin/out_elasticsearch.rb:408:in `write'
  2021-08-21 14:56:52 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:1096:in `try_flush'
  2021-08-21 14:56:52 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:1329:in `flush_thread_run'
  2021-08-21 14:56:52 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin/output.rb:439:in `block (2 levels) in start'
  2021-08-21 14:56:52 +0000 [warn]: #0 /usr/lib/ruby/gems/2.4.0/gems/fluentd-1.1.3/lib/fluent/plugin_helper/thread.rb:78:in `block in thread_create'
2021-08-21 14:56:53 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-08-21 14:56:53 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:56:53 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 14:56:54 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-08-21 14:56:54 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:56:54 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 14:56:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-08-21 14:56:56 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:56:56 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 14:57:00 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-08-21 14:57:00 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:57:00 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 14:57:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-08-21 14:57:08 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:57:08 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 14:57:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-08-21 14:57:22 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:57:22 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 14:57:53 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-08-21 14:57:53 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:57:53 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 14:58:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-08-21 14:58:56 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 14:58:56 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 15:01:02 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-08-21 15:01:02 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 15:01:02 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 15:04:57 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-08-21 15:04:57 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 15:04:57 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 15:13:53 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-08-21 15:13:53 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 15:13:53 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 15:30:35 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-08-21 15:30:35 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 15:30:35 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 16:02:23 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-08-21 16:02:23 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 16:02:23 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 17:08:30 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-08-21 17:08:30 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 17:08:30 +0000 [warn]: #0 suppressed same stacktrace
2021-08-21 19:26:07 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-08-21 19:26:07 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-21 19:26:07 +0000 [warn]: #0 suppressed same stacktrace
2021-08-22 00:07:35 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-08-22 00:07:35 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-22 00:07:35 +0000 [warn]: #0 suppressed same stacktrace
2021-08-22 00:28:03 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-22 00:28:05 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-08-22 00:28:05 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-08-22 00:28:05 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-22 00:28:06 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03\xFE\x05\x81\x1D\xD35Q\x94&\xE6\xD9\xDE\bK\x90\xE8\x85\xCACY\x89w'<\xE5\x14w-(\a,\x03 $\xBDj\x97m\x15\xE2#\x18\xDE\xE3\a\x06\xCD\xBB\xFBx\x17\x89\xEA\xC8a\xD2\xFDm\xDC\x89\xA6d\x1Cg=\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-08-22 00:28:06 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-08-22 00:28:06 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-08-22 00:28:06 +0000 [warn]: #0 failed to parse message data="\x00"
2021-08-22 00:28:06 +0000 [warn]: #0 failed to parse message data="\x00\b\x00\x1D\x00\x17\x00\x18\x00\x19\x00\v\x00\x02\x01\x00\x00\r\x00\x1A\x00\x18\b\x04\x04\x03\b\a\b\x05\b\x06\x04\x01\x05\x01\x06\x01\x05\x03\x06\x03\x02\x01\x02\x03\xFF\x01\x00\x01\x00\x00\x12\x00\x00\x00+\x00\t\b\x03\x04\x03\x03\x03\x02\x03\x01\x003\x00&\x00$\x00\x1D\x00 "
2021-08-22 09:26:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-08-22 09:26:56 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-22 09:26:56 +0000 [warn]: #0 suppressed same stacktrace
2021-08-22 18:59:32 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-08-22 20:15:04 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-08-23 02:16:32 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-08-23 02:16:32 +0000 chunk="5ca12fe68db4b135178e3e77d8dee45b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-23 02:16:32 +0000 [warn]: #0 suppressed same stacktrace
2021-08-23 17:53:11 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03sX\x033\xF8\xA7X\x17\xF3\x82\x11\xBC@AK"
2021-08-23 17:53:11 +0000 [warn]: #0 failed to parse message data="X\xF7d\x84\x9D\x1AE`|\xB65\x02_=\x04\x12\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-08-23 17:53:11 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-08-23 17:53:11 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-08-23 17:53:15 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-08-23 17:53:15 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-08-23 17:53:15 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-24 14:56:52 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=18 records=5 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-24 14:56:52 +0000 [error]: #0 suppressed same stacktrace
2021-08-25 19:28:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-08-25 19:28:06 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:28:05 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:28:06 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-08-25 19:28:06 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:28:06 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:28:07 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-08-25 19:28:07 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:28:07 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:28:09 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-08-25 19:28:09 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:28:09 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:28:13 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-08-25 19:28:13 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:28:13 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:28:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-08-25 19:28:22 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:28:22 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:28:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-08-25 19:28:38 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:28:38 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:29:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-08-25 19:29:08 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:29:08 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:30:15 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-08-25 19:30:15 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:30:15 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:32:27 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-08-25 19:32:27 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:32:27 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:37:13 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-08-25 19:37:13 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:37:13 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 19:46:25 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-08-25 19:46:25 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 19:46:25 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 20:02:33 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-08-25 20:02:33 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 20:02:33 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 20:40:34 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-08-25 20:40:34 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 20:40:34 +0000 [warn]: #0 suppressed same stacktrace
2021-08-25 21:50:52 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-08-25 21:50:52 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-25 21:50:52 +0000 [warn]: #0 suppressed same stacktrace
2021-08-26 00:21:14 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-08-26 00:21:14 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-26 00:21:14 +0000 [warn]: #0 suppressed same stacktrace
2021-08-26 04:28:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-08-26 04:28:22 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-26 04:28:22 +0000 [warn]: #0 suppressed same stacktrace
2021-08-26 14:42:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-08-26 14:42:11 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-26 14:42:11 +0000 [warn]: #0 suppressed same stacktrace
2021-08-26 17:41:57 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03\xAC \x06\xA6\v\x81\xDB\xAA\xC0\xCCz\xB7\x1D6\x83\x88.\x97\xEE\x1DX\"K\xB70\xA3\x8B\xA0T0\x89b\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-08-26 17:41:57 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-08-26 17:41:57 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-08-26 17:42:02 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-08-26 17:42:02 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-08-26 17:42:02 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-26 20:36:45 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03\xEC\x1Ao\xB3\xB3\x92\x14\".\xC1)\xC2\xC2\xFB\xFD\xFD\xA5n\x84Z\x9B\xECYR\x83g\xEC\x02N\xED b\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-08-26 20:36:45 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-08-26 20:36:45 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-08-26 20:36:49 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-08-26 20:36:49 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-08-26 20:36:49 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-27 08:39:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-08-27 08:39:22 +0000 chunk="5ca673fbc5aa7c536f92a163d16e4b84" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-27 08:39:22 +0000 [warn]: #0 suppressed same stacktrace
2021-08-27 16:05:04 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-27 16:10:43 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-27 16:10:45 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-08-27 16:10:45 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-08-27 16:10:45 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-27 16:10:46 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03A\xC7\xDC\xBE\xBCm\xF2<\xDFb\xFFscN\x95\xB7\xA8\xFE\xC3\x14\xB5\xDC\x80\x97\x99p\x8B-\xEA_\xB5w u\xEC\xD53\xD4\xAB+\xED\xEB^\xBD\xE8;\xC9C\xDD\x96\xAF!\x14\xE9/\xC2\xD7\x97qi\xEB\xAB\xD9\xE9a\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-08-27 16:10:46 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-08-27 16:10:46 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-08-27 16:10:46 +0000 [warn]: #0 failed to parse message data="\x00"
2021-08-28 19:28:06 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=18 records=3 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 19:28:06 +0000 [error]: #0 suppressed same stacktrace
2021-08-28 22:24:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-08-28 22:24:56 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:24:55 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:24:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-08-28 22:24:56 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:24:56 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:25:00 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-08-28 22:24:57 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:25:00 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:25:02 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-08-28 22:25:02 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:25:02 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:25:06 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-08-28 22:25:06 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:25:06 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:25:13 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-08-28 22:25:13 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:25:13 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:25:29 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-08-28 22:25:28 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:25:29 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:26:03 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-08-28 22:26:03 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:26:03 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:27:03 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-08-28 22:27:03 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:27:03 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:29:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-08-28 22:29:04 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:29:05 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:33:43 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-08-28 22:33:43 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:33:43 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:42:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-08-28 22:42:55 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:42:55 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 22:59:59 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-08-28 22:59:59 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 22:59:59 +0000 [warn]: #0 suppressed same stacktrace
2021-08-28 23:35:02 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-08-28 23:35:02 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-28 23:35:02 +0000 [warn]: #0 suppressed same stacktrace
2021-08-29 00:39:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-08-29 00:39:08 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-29 00:39:08 +0000 [warn]: #0 suppressed same stacktrace
2021-08-29 02:43:54 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-08-29 02:43:53 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-29 02:43:54 +0000 [warn]: #0 suppressed same stacktrace
2021-08-29 07:17:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-08-29 07:17:38 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-29 07:17:38 +0000 [warn]: #0 suppressed same stacktrace
2021-08-29 16:28:07 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-08-29 16:28:07 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-29 16:28:07 +0000 [warn]: #0 suppressed same stacktrace
2021-08-29 16:53:15 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x035\e\xB0d\x11=\x9A\xAB\xF5\xEE\xA7\x97 \xD4rA3\x9B\xBC\xA5\x05\xEE4\xB7[\x87\x8A~4\x86\xB9"
2021-08-29 16:53:15 +0000 [warn]: #0 failed to parse message data="\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-08-29 16:53:15 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-08-29 16:53:15 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-08-29 16:53:19 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-08-29 16:53:19 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-08-29 16:53:19 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-30 09:29:35 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-08-30 09:29:35 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-30 09:29:35 +0000 [warn]: #0 suppressed same stacktrace
2021-08-30 15:29:42 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-31 03:33:03 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-08-31 20:06:20 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-31 20:06:22 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-08-31 20:06:22 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-08-31 20:06:22 +0000 [warn]: #0 failed to parse message data="\r"
2021-08-31 22:11:53 +0000 [warn]: #0 failed to flush the buffer. retry_time=18 next_retry_seconds=2021-08-31 22:11:53 +0000 chunk="5caa611b689e597e3f62113edb87d84b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-31 22:11:53 +0000 [warn]: #0 suppressed same stacktrace
2021-08-31 22:24:58 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=19 records=2 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-08-31 22:24:58 +0000 [error]: #0 suppressed same stacktrace
2021-09-01 01:54:37 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-09-01 01:54:38 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:54:37 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:54:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-09-01 01:54:38 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:54:38 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:54:39 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-09-01 01:54:39 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:54:39 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:54:41 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-09-01 01:54:41 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:54:41 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:54:45 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-09-01 01:54:45 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:54:45 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:54:54 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-09-01 01:54:54 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:54:54 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:55:09 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-09-01 01:55:09 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:55:09 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:55:49 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-09-01 01:55:44 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:55:49 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:56:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-09-01 01:56:55 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:56:55 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 01:59:01 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-09-01 01:59:01 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 01:59:01 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 02:03:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-09-01 02:03:11 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 02:03:11 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 02:12:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-09-01 02:12:11 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 02:12:11 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 02:28:00 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-09-01 02:28:00 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 02:28:00 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 03:02:01 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-09-01 03:01:58 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 03:02:01 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 04:15:40 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-09-01 04:15:40 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 04:15:40 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 06:28:54 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-09-01 06:28:54 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 06:28:54 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 11:29:35 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-09-01 11:29:35 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 11:29:35 +0000 [warn]: #0 suppressed same stacktrace
2021-09-01 21:34:45 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-09-01 21:34:45 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-01 21:34:45 +0000 [warn]: #0 suppressed same stacktrace
2021-09-02 15:17:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-09-02 15:17:38 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-02 15:17:38 +0000 [warn]: #0 suppressed same stacktrace
2021-09-03 23:48:36 +0000 [warn]: #0 failed to flush the buffer. retry_time=18 next_retry_seconds=2021-09-03 23:48:36 +0000 chunk="5cae55938c5ac0f13b5f9998912d500a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-03 23:48:36 +0000 [warn]: #0 suppressed same stacktrace
2021-09-04 01:54:37 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=19 records=2 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-04 01:54:37 +0000 [error]: #0 suppressed same stacktrace
2021-09-06 16:30:40 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-09-06 16:30:41 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:30:40 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:30:41 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-09-06 16:30:41 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:30:41 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:30:42 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-09-06 16:30:42 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:30:42 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:30:44 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-09-06 16:30:44 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:30:44 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:30:48 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-09-06 16:30:48 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:30:48 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:30:57 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-09-06 16:30:57 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:30:57 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:31:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-09-06 16:31:11 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:31:11 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:31:43 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-09-06 16:31:43 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:31:43 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:32:45 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-09-06 16:32:45 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:32:45 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:35:00 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-09-06 16:35:00 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:35:00 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:39:35 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-09-06 16:39:35 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:39:35 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 16:48:47 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-09-06 16:48:47 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 16:48:47 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 17:04:30 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-09-06 17:04:30 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 17:04:30 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 17:39:28 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-09-06 17:39:28 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 17:39:28 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 18:44:00 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-09-06 18:44:00 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 18:44:00 +0000 [warn]: #0 suppressed same stacktrace
2021-09-06 21:06:17 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-09-06 21:06:17 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-06 21:06:17 +0000 [warn]: #0 suppressed same stacktrace
2021-09-07 01:18:43 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-09-07 01:18:43 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-07 01:18:43 +0000 [warn]: #0 suppressed same stacktrace
2021-09-07 10:38:19 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-09-07 10:38:19 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-07 10:38:19 +0000 [warn]: #0 suppressed same stacktrace
2021-09-08 04:52:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-09-08 04:52:05 +0000 chunk="5cb562b6288b10b44ab2e417c36171d2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-08 04:52:05 +0000 [warn]: #0 suppressed same stacktrace
2021-09-09 07:38:38 +0000 [warn]: #0 failed to parse message data="\r"
2021-09-09 07:38:40 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-09-09 07:38:40 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-09-09 07:38:40 +0000 [warn]: #0 failed to parse message data="\r"
2021-09-09 07:38:41 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03\xE1\rD\x91\x13\x9B\x8A\xF3\x80\x8D\xBD3\t\xCB\xBB=S\xE8_\x9Dp\xAD\xCBA\xF7\xAE\xE8\v/\xCEjr \xE0+39o\xF6'\xC8\aW\xEC5\x90\x96\x9Dn\xFB\x8F\t\azCF\x88\x1A\x15z\xC7\x9C\xB7\xB4\xB3\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-09-09 07:38:41 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-09-09 07:38:41 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-09-09 07:38:41 +0000 [warn]: #0 failed to parse message data="\x00"
2021-09-09 16:14:26 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00+&\xE0\x00\x00\x00\x00\x00Cookie: mstshash=hello\r"
2021-09-09 16:30:40 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=18 records=40 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-09 16:30:40 +0000 [error]: #0 suppressed same stacktrace
2021-09-13 20:46:39 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-09-13 20:46:40 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:46:39 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:46:40 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-09-13 20:46:40 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:46:40 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:46:41 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-09-13 20:46:41 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:46:41 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:46:43 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-09-13 20:46:43 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:46:43 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:46:47 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-09-13 20:46:47 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:46:47 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:46:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-09-13 20:46:56 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:46:56 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:47:12 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-09-13 20:47:12 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:47:12 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:47:48 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-09-13 20:47:48 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:47:48 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:48:47 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-09-13 20:48:47 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:48:47 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:50:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-09-13 20:50:56 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:50:56 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 20:55:00 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-09-13 20:55:00 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 20:55:00 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 21:03:49 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-09-13 21:03:49 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 21:03:49 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 21:19:41 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-09-13 21:19:41 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 21:19:41 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=3
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=47
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=42
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=-32
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=67
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=111
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=111
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=107
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=105
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=101
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=58
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=32
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=109
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=115
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=116
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=115
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=104
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=97
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=115
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=104
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=61
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=65
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=100
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=109
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=105
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=110
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=105
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=115
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=116
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=114
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=13
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=10
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=1
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=8
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=3
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:34:16 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.75.206" msg=0
2021-09-13 21:56:39 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-09-13 21:56:39 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 21:56:39 +0000 [warn]: #0 suppressed same stacktrace
2021-09-13 23:01:04 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-09-13 23:01:04 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-13 23:01:04 +0000 [warn]: #0 suppressed same stacktrace
2021-09-14 01:27:03 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-09-14 01:27:03 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-14 01:27:03 +0000 [warn]: #0 suppressed same stacktrace
2021-09-14 06:13:27 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-09-14 06:13:27 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-14 06:13:27 +0000 [warn]: #0 suppressed same stacktrace
2021-09-14 16:16:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-09-14 16:16:22 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-14 16:16:22 +0000 [warn]: #0 suppressed same stacktrace
2021-09-15 08:30:17 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-09-15 08:30:17 +0000 chunk="5cbe68fa25863e1083a4a7247bc2d802" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-15 08:30:17 +0000 [warn]: #0 suppressed same stacktrace
2021-09-16 20:46:39 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=18 records=2 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-16 20:46:39 +0000 [error]: #0 suppressed same stacktrace
2021-09-27 09:32:12 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-09-28 23:28:20 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-09-28 23:28:21 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:28:20 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:28:21 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-09-28 23:28:21 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:28:21 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:28:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-09-28 23:28:21 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:28:22 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:28:24 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-09-28 23:28:24 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:28:24 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:28:28 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-09-28 23:28:28 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:28:28 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:28:37 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-09-28 23:28:36 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:28:37 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:28:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-09-28 23:28:51 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:28:56 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:29:24 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-09-28 23:29:24 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:29:24 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:30:27 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-09-28 23:30:27 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:30:27 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:32:27 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-09-28 23:32:21 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:32:27 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:37:04 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-09-28 23:37:04 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:37:04 +0000 [warn]: #0 suppressed same stacktrace
2021-09-28 23:45:34 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-09-28 23:45:34 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-28 23:45:34 +0000 [warn]: #0 suppressed same stacktrace
2021-09-29 00:04:15 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-09-29 00:04:15 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-29 00:04:15 +0000 [warn]: #0 suppressed same stacktrace
2021-09-29 00:37:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-09-29 00:37:08 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-29 00:37:08 +0000 [warn]: #0 suppressed same stacktrace
2021-09-29 01:38:13 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-09-29 01:38:13 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-29 01:38:13 +0000 [warn]: #0 suppressed same stacktrace
2021-09-29 04:03:58 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-09-29 04:03:58 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-29 04:03:58 +0000 [warn]: #0 suppressed same stacktrace
2021-09-29 08:43:14 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-09-29 08:43:14 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-29 08:43:14 +0000 [warn]: #0 suppressed same stacktrace
2021-09-29 18:51:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-09-29 18:51:38 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-29 18:51:38 +0000 [warn]: #0 suppressed same stacktrace
2021-09-30 14:57:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-09-30 14:57:56 +0000 chunk="5cd16918d02c7b205ff894cb6c9de540" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-09-30 14:57:56 +0000 [warn]: #0 suppressed same stacktrace
2021-10-01 23:28:20 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=18 records=5 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-01 23:28:20 +0000 [error]: #0 suppressed same stacktrace
2021-10-02 13:57:36 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-10-02 13:57:37 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:57:36 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 13:57:37 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-10-02 13:57:37 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:57:37 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 13:57:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-10-02 13:57:38 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:57:38 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 13:57:40 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-10-02 13:57:40 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:57:40 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 13:57:49 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-10-02 13:57:44 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:57:49 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 13:57:57 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-10-02 13:57:57 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:57:57 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 13:58:15 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-10-02 13:58:15 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:58:15 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 13:58:51 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-10-02 13:58:51 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:58:51 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 13:59:57 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-10-02 13:59:57 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 13:59:57 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 14:02:09 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-10-02 14:02:09 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 14:02:09 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 14:06:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-10-02 14:06:55 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 14:06:55 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 14:14:32 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-10-02 14:14:32 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 14:14:32 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 14:29:45 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-10-02 14:29:45 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 14:29:45 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 15:06:48 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-10-02 15:06:48 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 15:06:48 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 16:21:13 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-10-02 16:21:13 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 16:21:13 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 18:21:37 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-10-02 18:21:37 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 18:21:37 +0000 [warn]: #0 suppressed same stacktrace
2021-10-02 22:45:02 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-10-02 22:45:02 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-02 22:45:02 +0000 [warn]: #0 suppressed same stacktrace
2021-10-03 07:24:13 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-10-03 07:24:13 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-03 07:24:13 +0000 [warn]: #0 suppressed same stacktrace
2021-10-04 00:46:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-10-04 00:46:11 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-04 00:46:11 +0000 [warn]: #0 suppressed same stacktrace
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=3
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=47
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=42
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=-32
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=67
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=111
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=111
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=107
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=105
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=101
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=58
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=32
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=109
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=115
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=116
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=115
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=104
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=97
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=115
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=104
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=61
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=65
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=100
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=109
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=105
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=110
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=105
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=115
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=116
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=114
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=13
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=10
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=1
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=8
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=3
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 05:57:31 +0000 [warn]: #0 [input1] incoming chunk is broken: host="45.146.166.233" msg=0
2021-10-05 10:15:33 +0000 [warn]: #0 failed to flush the buffer. retry_time=18 next_retry_seconds=2021-10-05 10:15:33 +0000 chunk="5cd5f0fca47a787b04f02c1633ff8675" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-05 10:15:33 +0000 [warn]: #0 suppressed same stacktrace
2021-10-05 13:57:36 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=19 records=1 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-05 13:57:36 +0000 [error]: #0 suppressed same stacktrace
2021-10-09 03:57:56 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-09 03:57:58 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-10-09 03:57:58 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-10-09 03:57:58 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-09 23:09:48 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03_\xCE9P\x02Q\xA0\xED\xAA\xB1\"\xC5MFw\x8F\x9F\x11\x92[\xB7\xA2\x10\x15\xBD09\x84;\xEE\xFB\xBD\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-10-09 23:09:48 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-10-09 23:09:48 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-10-09 23:09:52 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-10-09 23:09:52 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-10-09 23:09:52 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-09 23:16:19 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-09 23:16:20 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-10-09 23:16:20 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-10-09 23:16:20 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-09 23:16:22 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03H\xEA\x1E\x91\x9D\xCC\xBF\x80`r\xD1\xD3g\x858\x81C\aC)\x1A\xB8\xAC\xF2\x16\xE0\xF9\x9F\xB9\x91A& \x9D\xD7c86S$s\x91\xC2b\xDD$\x84D\x7Fcu\xBE\x0EV\t\x8Fp\xC9\x14}\xCCQ\f\x88\xC9\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-10-09 23:16:22 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-10-09 23:16:22 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-10-09 23:16:22 +0000 [warn]: #0 failed to parse message data="\x00"
2021-10-09 23:16:22 +0000 [warn]: #0 failed to parse message data="\x00\b\x00\x1D\x00\x17\x00\x18\x00\x19\x00\v\x00\x02\x01\x00\x00\r\x00\x1A\x00\x18\b\x04\x04\x03\b\a\b\x05\b\x06\x04\x01\x05\x01\x06\x01\x05\x03\x06\x03\x02\x01\x02\x03\xFF\x01\x00\x01\x00\x00\x12\x00\x00\x00+\x00\t\b\x03\x04\x03\x03\x03\x02\x03\x01\x003\x00&\x00$\x00\x1D\x00 \xDC\xD7\xC3\xC1o\x10\xFE\x01\x8D\xFAA\x87\xB9\xECn\xE9\xF3\xFC&\x84\xE9\xA7\xE2d\x1F"
2021-10-11 03:36:10 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-10-11 03:36:11 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:36:10 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:36:16 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-10-11 03:36:11 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:36:16 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:36:17 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-10-11 03:36:17 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:36:17 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:36:19 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-10-11 03:36:19 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:36:19 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:36:24 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-10-11 03:36:24 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:36:24 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:36:31 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-10-11 03:36:31 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:36:31 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:36:47 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-10-11 03:36:47 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:36:47 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:37:16 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-10-11 03:37:16 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:37:16 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:38:23 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-10-11 03:38:23 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:38:23 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:40:37 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-10-11 03:40:32 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:40:37 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:44:31 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-10-11 03:44:31 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:44:31 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 03:52:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-10-11 03:52:06 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 03:52:11 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 04:08:14 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-10-11 04:08:14 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 04:08:14 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 04:43:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-10-11 04:43:11 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 04:43:11 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 05:59:58 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-10-11 05:59:58 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 05:59:58 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 08:28:09 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-10-11 08:28:09 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 08:28:09 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 13:09:59 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-10-11 13:09:59 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 13:09:59 +0000 [warn]: #0 suppressed same stacktrace
2021-10-11 23:00:47 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-10-11 23:00:47 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-11 23:00:47 +0000 [warn]: #0 suppressed same stacktrace
2021-10-12 19:04:19 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-10-12 19:04:19 +0000 chunk="5ce0b6df1286910d37deb6acb8790a0a" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-12 19:04:19 +0000 [warn]: #0 suppressed same stacktrace
2021-10-14 03:36:10 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=18 records=2 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-14 03:36:10 +0000 [error]: #0 suppressed same stacktrace
2021-10-14 05:11:08 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-16 00:43:21 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-10-16 00:43:22 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:43:21 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:43:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-10-16 00:43:22 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:43:22 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:43:23 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-10-16 00:43:23 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:43:23 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:43:25 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-10-16 00:43:25 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:43:25 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:43:29 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-10-16 00:43:29 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:43:29 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:43:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-10-16 00:43:38 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:43:38 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:43:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-10-16 00:43:55 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:43:55 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:44:25 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-10-16 00:44:25 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:44:25 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:45:25 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-10-16 00:45:25 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:45:25 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:47:28 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-10-16 00:47:28 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:47:28 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:51:29 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-10-16 00:51:29 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:51:29 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 00:59:21 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-10-16 00:59:21 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 00:59:21 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 01:16:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-10-16 01:16:04 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 01:16:11 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 01:54:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-10-16 01:54:22 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 01:54:22 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 03:11:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-10-16 03:11:05 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 03:11:08 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 05:34:36 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-10-16 05:34:36 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 05:34:36 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 10:23:24 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-10-16 10:23:24 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 10:23:24 +0000 [warn]: #0 suppressed same stacktrace
2021-10-16 19:48:07 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-10-16 19:48:07 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-16 19:48:07 +0000 [warn]: #0 suppressed same stacktrace
2021-10-17 11:53:28 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-10-17 11:53:28 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-17 11:53:28 +0000 [warn]: #0 suppressed same stacktrace
2021-10-18 20:00:31 +0000 [warn]: #0 failed to flush the buffer. retry_time=18 next_retry_seconds=2021-10-18 20:00:31 +0000 chunk="5ce6d99276304839e255961f60767dc6" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-18 20:00:31 +0000 [warn]: #0 suppressed same stacktrace
2021-10-19 00:43:21 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=19 records=1 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-19 00:43:21 +0000 [error]: #0 suppressed same stacktrace
2021-10-21 10:32:46 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-10-25 00:44:21 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03\x9E\xC1\xB9\x01\a\x13\xDE\xE7\xC0\xB0\x02R\xE2f6\x05u\xC6M\xE4\xD7\a\xCA\xE1\x1D_\x87v\x86\xEC\\\xBB\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-10-25 00:44:21 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-10-25 00:44:21 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-10-25 00:44:25 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-10-25 00:44:25 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-10-25 00:44:25 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=3
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=47
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=42
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=-32
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=67
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=111
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=111
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=107
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=101
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=58
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=32
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=109
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=116
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=104
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=97
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=104
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=61
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=65
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=100
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=109
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=110
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=116
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=114
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=13
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=10
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=1
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=8
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=3
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 17:17:18 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=3
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=47
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=42
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=-32
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=67
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=111
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=111
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=107
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=101
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=58
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=32
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=109
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=116
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=104
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=97
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=104
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=61
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=65
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=100
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=109
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=110
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=105
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=115
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=116
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=114
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=13
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=10
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=1
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=8
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=3
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-25 19:28:06 +0000 [warn]: #0 [input1] incoming chunk is broken: host="87.251.67.40" msg=0
2021-10-26 23:06:54 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-26 23:06:56 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-10-26 23:06:56 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-10-26 23:06:56 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-26 23:06:58 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03W61=\xA6\xFD\x17\x8ApLR\xEF\xF2\xF9\xE0.~\xF9tQ1_\xCEF'\x81Q{\xAF\xBA\xAC\xC7 }\xA5#\x0E\x99\x1D\xB1I\xD0\x1D1\xB9!\xB9\x1E\xF0u\xC4\xA5t\xD5\x98*&k\x10J\\\xF3\x12\xD4F\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-10-26 23:06:58 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-10-26 23:06:58 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-10-26 23:06:58 +0000 [warn]: #0 failed to parse message data="\x00"
2021-10-27 19:50:39 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-27 19:50:40 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-10-27 19:50:40 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-10-27 19:50:40 +0000 [warn]: #0 failed to parse message data="\r"
2021-10-27 19:50:41 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03\x820\x86\xC8\xFD\xB5/\xE2z\x94\x0E\xB8\xB8B:\xAE\xE79\x06K\xB3\xD0\x8F\xF3Fy\x89=\xEE\xCCa\xE6 D`\x06\x11\xF1\xC1(&\x8C\xB4,\x98(v\xC7\xAEy\xB2\xDB\xD9\x14{T\xCD\xEB\xEE\x129\xF7\xB6\xB3\xF4\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-10-27 19:50:41 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-10-27 19:50:41 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-10-27 19:50:41 +0000 [warn]: #0 failed to parse message data="\x00"
2021-10-28 16:09:24 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-10-28 19:31:43 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-10-29 06:54:29 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-10-29 06:54:30 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:54:29 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:54:30 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-10-29 06:54:30 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:54:30 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:54:31 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-10-29 06:54:31 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:54:31 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:54:33 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-10-29 06:54:33 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:54:33 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:54:37 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-10-29 06:54:37 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:54:37 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:54:46 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-10-29 06:54:45 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:54:46 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:55:03 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-10-29 06:55:03 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:55:03 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:55:33 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-10-29 06:55:33 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:55:33 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:56:34 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-10-29 06:56:34 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:56:34 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 06:58:31 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-10-29 06:58:31 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 06:58:31 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 07:02:42 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-10-29 07:02:42 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 07:02:42 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 07:10:49 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-10-29 07:10:49 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 07:10:49 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 07:27:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-10-29 07:27:08 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 07:27:08 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 08:02:31 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-10-29 08:02:26 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 08:02:31 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 09:17:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-10-29 09:17:05 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 09:17:05 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 11:31:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-10-29 11:31:05 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 11:31:05 +0000 [warn]: #0 suppressed same stacktrace
2021-10-29 16:01:28 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-10-29 16:01:16 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-29 16:01:28 +0000 [warn]: #0 suppressed same stacktrace
2021-10-30 00:47:26 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-10-30 00:47:26 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-30 00:47:26 +0000 [warn]: #0 suppressed same stacktrace
2021-10-30 20:25:15 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-10-30 20:25:15 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-10-30 20:25:15 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 04:21:51 +0000 [warn]: #0 failed to flush the buffer. retry_time=18 next_retry_seconds=2021-11-01 04:21:46 +0000 chunk="5cf784c537cbfdea8a7eed82b704c0e2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 04:21:51 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 06:54:29 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=19 records=2 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 06:54:29 +0000 [error]: #0 suppressed same stacktrace
2021-11-01 23:02:29 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-01 23:02:30 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:02:29 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:02:30 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-01 23:02:30 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:02:30 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:02:31 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-11-01 23:02:31 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:02:31 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:02:33 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-11-01 23:02:33 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:02:33 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:02:37 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-11-01 23:02:37 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:02:37 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:02:44 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-11-01 23:02:44 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:02:44 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:02:59 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-11-01 23:02:59 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:02:59 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:03:32 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-11-01 23:03:32 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:03:32 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:04:39 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-11-01 23:04:39 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:04:39 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:06:44 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-11-01 23:06:44 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:06:44 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:11:23 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-11-01 23:11:23 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:11:23 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:19:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-11-01 23:19:11 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:19:11 +0000 [warn]: #0 suppressed same stacktrace
2021-11-01 23:38:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-11-01 23:38:08 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-01 23:38:08 +0000 [warn]: #0 suppressed same stacktrace
2021-11-02 00:10:35 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-11-02 00:10:35 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-02 00:10:35 +0000 [warn]: #0 suppressed same stacktrace
2021-11-02 01:21:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-11-02 01:21:04 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-02 01:21:05 +0000 [warn]: #0 suppressed same stacktrace
2021-11-02 03:28:54 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-11-02 03:28:54 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-02 03:28:54 +0000 [warn]: #0 suppressed same stacktrace
2021-11-02 07:31:43 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-11-02 07:31:43 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-02 07:31:43 +0000 [warn]: #0 suppressed same stacktrace
2021-11-02 16:52:23 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-11-02 16:52:23 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-02 16:52:23 +0000 [warn]: #0 suppressed same stacktrace
2021-11-03 08:50:01 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-11-03 08:50:01 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-03 08:50:01 +0000 [warn]: #0 suppressed same stacktrace
2021-11-04 20:14:42 +0000 [warn]: #0 failed to flush the buffer. retry_time=18 next_retry_seconds=2021-11-04 20:14:42 +0000 chunk="5cfc22bb00c3e6e4c80f84d3bc360fa2" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-04 20:14:42 +0000 [warn]: #0 suppressed same stacktrace
2021-11-04 23:02:29 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=19 records=1 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-04 23:02:29 +0000 [error]: #0 suppressed same stacktrace
2021-11-05 10:48:47 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-05 10:48:48 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:48:47 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:48:48 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-05 10:48:48 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:48:48 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:48:49 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-11-05 10:48:49 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:48:49 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:48:59 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-11-05 10:48:51 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:48:59 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:49:03 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-11-05 10:49:03 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:49:03 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:49:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-11-05 10:49:11 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:49:11 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:49:25 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-11-05 10:49:25 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:49:25 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:49:54 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-11-05 10:49:54 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:49:54 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:51:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-11-05 10:51:05 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:51:05 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:53:02 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-11-05 10:53:02 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:53:02 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 10:57:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-11-05 10:57:05 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 10:57:08 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 11:04:45 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-11-05 11:04:45 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 11:04:45 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 11:23:30 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-11-05 11:23:30 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 11:23:30 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 12:01:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-11-05 12:01:38 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 12:01:38 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 13:04:12 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-11-05 13:04:12 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 13:04:12 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 15:32:13 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-11-05 15:32:13 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 15:32:13 +0000 [warn]: #0 suppressed same stacktrace
2021-11-05 20:28:18 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-11-05 20:28:18 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-05 20:28:18 +0000 [warn]: #0 suppressed same stacktrace
2021-11-06 05:10:10 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-11-06 05:10:10 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-06 05:10:10 +0000 [warn]: #0 suppressed same stacktrace
2021-11-06 06:49:30 +0000 [warn]: #0 failed to parse message data="\r"
2021-11-06 21:28:35 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-11-06 21:28:35 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-06 21:28:35 +0000 [warn]: #0 suppressed same stacktrace
2021-11-08 07:31:39 +0000 [warn]: #0 failed to flush the buffer. retry_time=18 next_retry_seconds=2021-11-08 07:31:39 +0000 chunk="5d00863218529ac97f63abba4983bd8b" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-08 07:31:39 +0000 [warn]: #0 suppressed same stacktrace
2021-11-08 10:48:47 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=19 records=4 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-08 10:48:47 +0000 [error]: #0 suppressed same stacktrace
2021-11-09 05:28:47 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-09 05:28:48 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:28:47 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:28:48 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-09 05:28:48 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:28:48 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:28:49 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-11-09 05:28:49 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:28:49 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:28:51 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-11-09 05:28:51 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:28:51 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:28:56 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-11-09 05:28:56 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:28:56 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:29:04 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-11-09 05:29:03 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:29:04 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:29:21 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-11-09 05:29:21 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:29:21 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:29:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-11-09 05:29:55 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:29:55 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:30:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-11-09 05:30:55 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:30:55 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:33:00 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-11-09 05:33:00 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:33:00 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:36:46 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-11-09 05:36:46 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:36:46 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 05:44:29 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-11-09 05:44:29 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 05:44:29 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 06:03:09 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-11-09 06:03:09 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 06:03:09 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 06:37:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-11-09 06:36:59 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 06:37:05 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 07:51:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-11-09 07:51:22 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 07:51:22 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 10:07:29 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-11-09 10:07:29 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 10:07:29 +0000 [warn]: #0 suppressed same stacktrace
2021-11-09 14:58:40 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-11-09 14:58:40 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-09 14:58:40 +0000 [warn]: #0 suppressed same stacktrace
2021-11-10 01:11:26 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-11-10 01:11:26 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-10 01:11:26 +0000 [warn]: #0 suppressed same stacktrace
2021-11-10 17:43:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-11-10 17:43:22 +0000 chunk="5d0546228081d833882110380d4aa568" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-10 17:43:22 +0000 [warn]: #0 suppressed same stacktrace
2021-11-12 05:28:47 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=18 records=1 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-12 05:28:47 +0000 [error]: #0 suppressed same stacktrace
2021-11-14 04:25:53 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-14 04:25:54 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:25:53 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:25:54 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-14 04:25:54 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:25:54 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:25:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-11-14 04:25:55 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:25:55 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:25:57 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-11-14 04:25:57 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:25:57 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:26:01 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-11-14 04:26:01 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:26:01 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:26:35 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-11-14 04:26:09 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:26:35 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:26:50 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-11-14 04:26:50 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:26:50 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:27:20 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-11-14 04:27:20 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:27:20 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:28:42 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-11-14 04:28:31 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:28:42 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:31:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-11-14 04:31:05 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:31:05 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:35:49 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-11-14 04:35:49 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:35:49 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 04:44:33 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-11-14 04:44:33 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 04:44:33 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 05:03:09 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-11-14 05:03:09 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 05:03:09 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 05:34:45 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-11-14 05:34:45 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 05:34:45 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 06:44:40 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-11-14 06:44:34 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 06:44:40 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 08:46:15 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-11-14 08:46:15 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 08:46:15 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 12:49:12 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-11-14 12:49:12 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 12:49:12 +0000 [warn]: #0 suppressed same stacktrace
2021-11-14 22:07:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-11-14 22:07:55 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-14 22:07:55 +0000 [warn]: #0 suppressed same stacktrace
2021-11-15 14:42:38 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-11-15 14:42:38 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-15 14:42:38 +0000 [warn]: #0 suppressed same stacktrace
2021-11-16 00:58:37 +0000 [warn]: #0 failed to parse message data="\r"
2021-11-16 00:58:39 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-11-16 00:58:39 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-11-16 00:58:39 +0000 [warn]: #0 failed to parse message data="\r"
2021-11-16 00:58:40 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03\xC4\x8F\x95H\xEC\x1A\x87\x850#\x12\xBF\x85\x87D\x15|\xE4^\xED\xB3,H\xE5\x8Fq~-\xB6%t! \xB2\xA6\xE5\x9B\xC1\x98\x12C-xN\xAF\xC2M\xDD\xAE\x84#\xB16+\x83\xDE\x00$\xC8X\x7FG=\xCB\xDC\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-11-16 00:58:40 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-11-16 00:58:40 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-11-16 00:58:40 +0000 [warn]: #0 failed to parse message data="\x00"
2021-11-16 00:58:40 +0000 [warn]: #0 failed to parse message data="\x00\b\x00\x1D\x00\x17\x00\x18\x00\x19\x00\v\x00\x02\x01\x00\x00\r\x00\x1A\x00\x18\b\x04\x04\x03\b\a\b\x05\b\x06\x04\x01\x05\x01\x06\x01\x05\x03\x06\x03\x02\x01\x02\x03\xFF\x01\x00\x01\x00\x00\x12\x00\x00\x00+\x00\t\b\x03\x04\x03\x03\x03\x02\x03\x01\x003\x00&\x00$\x00\x1D\x00 U\x8Au\tG\xC0\xBCbC\xFE\x13\xD2\xAC\xA2du@\x8E\xB8\xF5\xCD\x0Ep\x88c\x9A\xB6\x87\xCA"
2021-11-17 03:38:22 +0000 [warn]: #0 failed to flush the buffer. retry_time=18 next_retry_seconds=2021-11-17 03:38:21 +0000 chunk="5d0b816694229511705433a7fd6ee320" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-17 03:38:22 +0000 [warn]: #0 suppressed same stacktrace
2021-11-17 04:25:53 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=19 records=1 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-17 04:25:53 +0000 [error]: #0 suppressed same stacktrace
2021-11-18 11:36:19 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-18 11:36:20 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:36:19 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:36:20 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-18 11:36:20 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:36:20 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:36:21 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-11-18 11:36:21 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:36:21 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:36:23 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-11-18 11:36:23 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:36:23 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:36:27 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-11-18 11:36:27 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:36:27 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:36:36 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-11-18 11:36:36 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:36:36 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:36:51 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-11-18 11:36:51 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:36:51 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:37:31 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-11-18 11:37:23 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:37:31 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:38:27 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-11-18 11:38:27 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:38:27 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:40:44 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-11-18 11:40:44 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:40:44 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:45:12 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-11-18 11:45:12 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:45:12 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 11:54:29 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-11-18 11:54:29 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 11:54:29 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 12:12:55 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-11-18 12:12:52 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 12:12:55 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 12:43:40 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-11-18 12:43:40 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 12:43:40 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 13:43:52 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-11-18 13:43:52 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 13:43:52 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 15:53:52 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-11-18 15:53:49 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 15:53:52 +0000 [warn]: #0 suppressed same stacktrace
2021-11-18 19:53:23 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-11-18 19:53:23 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-18 19:53:23 +0000 [warn]: #0 suppressed same stacktrace
2021-11-19 03:51:43 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-11-19 03:51:43 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-19 03:51:43 +0000 [warn]: #0 suppressed same stacktrace
2021-11-19 15:03:58 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-11-19 18:57:16 +0000 [warn]: #0 failed to parse message data="\x03\x00\x00/*\xE0\x00\x00\x00\x00\x00Cookie: mstshash=Administr\r"
2021-11-20 00:10:51 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-11-20 00:10:51 +0000 chunk="5d10e9126a8d6e4afa61258cf2b9dab3" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-20 00:10:51 +0000 [warn]: #0 suppressed same stacktrace
2021-11-21 11:36:19 +0000 [error]: #0 failed to flush the buffer, and hit limit for retries. dropping all chunks in the buffer queue. retry_times=18 records=2 error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-21 11:36:19 +0000 [error]: #0 suppressed same stacktrace
2021-11-23 08:15:43 +0000 [warn]: #0 failed to parse message data="\r"
2021-11-23 08:15:45 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-11-23 08:15:45 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-11-23 08:15:45 +0000 [warn]: #0 failed to parse message data="\r"
2021-11-23 08:15:47 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03\xDF\x86nTAx\t\x01AA\xD5@\xF1b\x92\xF5\xE4z:\xB0\x1A"
2021-11-23 08:15:47 +0000 [warn]: #0 failed to parse message data="$6c\xDC\xD7Z\xFC\x13Z/ \x1F\v,\x11x>QM\x02\x93C\xF7\xC0w\xF5\xF2~\x8Bq\x14\xD4\xFD\x89\xEB"
2021-11-23 08:15:47 +0000 [warn]: #0 failed to parse message data=" \xFE\xC3\xF3^`e\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-11-23 08:15:47 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-11-23 08:15:47 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-11-23 08:15:47 +0000 [warn]: #0 failed to parse message data="\x00"
2021-11-30 08:03:03 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-30 08:03:04 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:03:03 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:03:04 +0000 [warn]: #0 failed to flush the buffer. retry_time=0 next_retry_seconds=2021-11-30 08:03:04 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:03:04 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:03:05 +0000 [warn]: #0 failed to flush the buffer. retry_time=1 next_retry_seconds=2021-11-30 08:03:05 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:03:05 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:03:07 +0000 [warn]: #0 failed to flush the buffer. retry_time=2 next_retry_seconds=2021-11-30 08:03:07 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:03:07 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:03:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=3 next_retry_seconds=2021-11-30 08:03:11 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:03:11 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:03:19 +0000 [warn]: #0 failed to flush the buffer. retry_time=4 next_retry_seconds=2021-11-30 08:03:19 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:03:19 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:03:37 +0000 [warn]: #0 failed to flush the buffer. retry_time=5 next_retry_seconds=2021-11-30 08:03:37 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:03:37 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:04:08 +0000 [warn]: #0 failed to flush the buffer. retry_time=6 next_retry_seconds=2021-11-30 08:04:08 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:04:08 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:05:06 +0000 [warn]: #0 failed to flush the buffer. retry_time=7 next_retry_seconds=2021-11-30 08:05:06 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:05:06 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:07:17 +0000 [warn]: #0 failed to flush the buffer. retry_time=8 next_retry_seconds=2021-11-30 08:07:17 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:07:17 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:11:28 +0000 [warn]: #0 failed to flush the buffer. retry_time=9 next_retry_seconds=2021-11-30 08:11:28 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:11:28 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:20:11 +0000 [warn]: #0 failed to flush the buffer. retry_time=10 next_retry_seconds=2021-11-30 08:20:11 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:20:11 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 08:36:27 +0000 [warn]: #0 failed to flush the buffer. retry_time=11 next_retry_seconds=2021-11-30 08:36:27 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 08:36:27 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 09:09:01 +0000 [warn]: #0 failed to flush the buffer. retry_time=12 next_retry_seconds=2021-11-30 09:09:01 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 09:09:01 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 10:14:40 +0000 [warn]: #0 failed to flush the buffer. retry_time=13 next_retry_seconds=2021-11-30 10:14:40 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 10:14:40 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 12:33:52 +0000 [warn]: #0 failed to flush the buffer. retry_time=14 next_retry_seconds=2021-11-30 12:33:52 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 12:33:52 +0000 [warn]: #0 suppressed same stacktrace
2021-11-30 16:33:58 +0000 [warn]: #0 failed to flush the buffer. retry_time=15 next_retry_seconds=2021-11-30 16:33:57 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-11-30 16:33:58 +0000 [warn]: #0 suppressed same stacktrace
2021-12-01 02:23:24 +0000 [warn]: #0 failed to flush the buffer. retry_time=16 next_retry_seconds=2021-12-01 02:23:23 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-12-01 02:23:24 +0000 [warn]: #0 suppressed same stacktrace
2021-12-01 03:09:19 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00{\x01\x00\x00w\x03\x03\x1CFM[\xE4F\xDA\xBB\xA8\xED\r\x98\x8B\xDB\x84_\xB7_\xB7\t\x9F1[\xDAy\x01\xA2\x92\xA1\""
2021-12-01 03:09:19 +0000 [warn]: #0 failed to parse message data="7\x00\x00\x1A\xC0/\xC0+\xC0\x11\xC0\a\xC0\x13\xC0\t\xC0\x14\xC0"
2021-12-01 03:09:19 +0000 [warn]: #0 failed to parse message data="\x00\x05\x00/\x005\xC0\x12\x00"
2021-12-01 03:09:19 +0000 [warn]: #0 failed to parse message data="\x01\x00\x004\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-12-01 03:09:24 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-12-01 03:09:24 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-12-01 03:09:24 +0000 [warn]: #0 failed to parse message data="\r"
2021-12-01 03:15:16 +0000 [warn]: #0 failed to parse message data="\r"
2021-12-01 03:15:17 +0000 [warn]: #0 failed to parse message data="GET / HTTP/1.1\r"
2021-12-01 03:15:17 +0000 [warn]: #0 failed to parse message data="Host: 129.232.230.131:5140\r"
2021-12-01 03:15:17 +0000 [warn]: #0 failed to parse message data="\r"
2021-12-01 03:15:19 +0000 [warn]: #0 failed to parse message data="\x16\x03\x01\x00\xEE\x01\x00\x00\xEA\x03\x03\xBB/\x84\xFC=\xE0\xFEF\x8D\xF8\xB9z\xBC9\xDD\xB8\xF9>4\xEC\x8C=3\x80B^\r\xCD\xEFFG\xAA \xD9\x7F\x98\xDC\x00d\xB8\xDC.%\xDBU\t|\x8D\xFA\xA0\xAE\xB9\x0E{{\xCD\xE0\xFEF@\xF0G7\x1E\xFB\x00&\xC0/\xC00\xC0+\xC0,\xCC\xA8\xCC\xA9\xC0\x13\xC0\t\xC0\x14\xC0"
2021-12-01 03:15:19 +0000 [warn]: #0 failed to parse message data="\x00\x9C\x00\x9D\x00/\x005\xC0\x12\x00"
2021-12-01 03:15:19 +0000 [warn]: #0 failed to parse message data="\x13\x01\x13\x03\x13\x02\x01\x00\x00{\x00\x05\x00\x05\x01\x00\x00\x00\x00\x00"
2021-12-01 03:15:19 +0000 [warn]: #0 failed to parse message data="\x00"
2021-12-01 20:17:24 +0000 [warn]: #0 failed to flush the buffer. retry_time=17 next_retry_seconds=2021-12-01 20:17:24 +0000 chunk="5d1fcfb518aed22314ae64d94a5bfea9" error_class=Fluent::Plugin::ElasticsearchOutput::ConnectionFailure error="Can not reach Elasticsearch cluster ({:host=>\"elasticsearch\", :port=>9200, :scheme=>\"http\"})!"
  2021-12-01 20:17:24 +0000 [warn]: #0 suppressed same stacktrace
